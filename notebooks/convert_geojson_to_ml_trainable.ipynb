{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:35:22.590898Z",
     "start_time": "2018-10-03T05:35:22.585256Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from osgeo import gdal\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import os \n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:35:23.255718Z",
     "start_time": "2018-10-03T05:35:23.248647Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"images/niihau\", 0755)  \n",
    "except OSError:\n",
    "    print(\"folder already exists\")\n",
    "\n",
    "try:\n",
    "    os.makedirs(\"niihau\", 0755)  \n",
    "except OSError:\n",
    "    print(\"folder already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:35:23.897428Z",
     "start_time": "2018-10-03T05:35:23.891555Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "root_folder = os.getcwd()\n",
    "root_folder = \"/tmp\"\n",
    "print(root_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:35:47.986505Z",
     "start_time": "2018-10-03T05:35:24.522476Z"
    }
   },
   "outputs": [],
   "source": [
    "not_default_keys = True\n",
    "\n",
    "import boto3 \n",
    "boto3.setup_default_session(profile_name='hawaii')\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "version='v2'\n",
    "\n",
    "bucket_name = 'hawaii-marine-debris'\n",
    "file_path_template = \"{}/jpg/{}\"\n",
    "downloaded_tile = set()\n",
    "csv_rows = []\n",
    "islands= ['niihau']#'lanai','bigisland',''\n",
    "local_tmp_folder = \"/tmp/{}\"\n",
    "\n",
    "annotatino_s3key_path = \"{island}/annotations.csv\"\n",
    "geojson_keys = [\n",
    "    \"niihau/final_marine_debris_database_NI_UTM4N_boxes.geojson\",\n",
    "    \"niihau/niihau_tileindex.geojson\",    \n",
    "]\n",
    "\n",
    "\n",
    "s3_resource.Bucket(bucket_name).download_file(\"niihau/final_marine_debris_database_NI_UTM4N_boxes.geojson\", \"{}/final_marine_debris_database_NI_UTM4N_boxes.geojson\".format(root_folder))\n",
    "s3_resource.Bucket(bucket_name).download_file(\"niihau/niihau_tileindex.geojson\", \"{}/niihau_tileindex.geojson\".format(root_folder))\n",
    "s3_resource.Bucket(bucket_name).download_file(\"niihau/deduped_annotations.csv\", \"{}/niihau/annotations.csv\".format(root_folder))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:35:47.989002Z",
     "start_time": "2018-10-03T12:35:37.478Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3_resource.Bucket(bucket_name).download_file(\"niihau/niihau_tileindex.csv\", \"{}/niihau_tileindex.csv\".format(root_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T16:13:10.876220Z",
     "start_time": "2018-10-02T16:13:09.994909Z"
    }
   },
   "outputs": [],
   "source": [
    "tile_index_df = pd.read_csv(\"{}/niihau_tileindex.csv\".format(root_folder))\n",
    "len(tile_index_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:35:58.680537Z",
     "start_time": "2018-10-03T05:35:56.854239Z"
    }
   },
   "outputs": [],
   "source": [
    "s3_resource.Bucket(bucket_name).download_file(\"niihau/deduped_annotations.csv\", \"{}/niihau/annotations.csv\".format(root_folder))\n",
    "\n",
    "existing_annotation_df = pd.read_csv(\"{}/niihau/annotations.csv\".format(root_folder))\n",
    "existing_annotation_df['file_path'] = existing_annotation_df['s3_key'].replace({'niihau/jpg': '{}/niihau/images'.format(root_folder)}, inplace=False, regex=True)\n",
    "existing_annotation_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:36:01.943319Z",
     "start_time": "2018-10-03T05:36:01.893693Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_from_s3(s3_key):\n",
    "    basename = os.path.basename(s3_key)\n",
    "    local_file_path = local_tmp_folder.format(basename)\n",
    "    s3_resource.Bucket(bucket_name).download_file(s3_key, local_file_path)\n",
    "    return local_file_path\n",
    "\n",
    "def convert_tif_to_jpeg(tiff_image_path):\n",
    "    src = rasterio.open(tiff_image_path)\n",
    "    jpg_path = tiff_image_path.replace(\".tif\", \".jpg\")\n",
    "    data = src.read()\n",
    "    profile = src.profile\n",
    "    result = data.astype(rasterio.uint8, casting='unsafe', copy=False)\n",
    "    profile.update(driver='jpeg')\n",
    "    with rasterio.open(jpg_path, 'w', **profile) as dst:\n",
    "        dst.write(result)\n",
    "    return jpg_path\n",
    "                \n",
    "def upload_to_s3(local_file_path, s3_path):\n",
    "    s3_client.upload_file(local_file_path, bucket_name, s3_path)\n",
    "\n",
    "def find_min_xy(coordinates):\n",
    "    x0 = min([i[0] for i in coordinates])\n",
    "    x1 = max([i[0] for i in coordinates])\n",
    "    y0 = min([i[1] for i in coordinates])\n",
    "    y1 = max([i[1] for i in coordinates])\n",
    "    return x0,y0,x1,y1\n",
    "\n",
    "\n",
    "def get_pixel_coordinates(image_path, coordinates):\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    dataset = gdal.Open(image_path)\n",
    "    band = dataset.GetRasterBand(1)\n",
    "\n",
    "    cols = dataset.RasterXSize\n",
    "    rows = dataset.RasterYSize\n",
    "\n",
    "    transform = dataset.GetGeoTransform()\n",
    "\n",
    "    xOrigin = transform[0]\n",
    "    yOrigin = transform[3]\n",
    "    pixelWidth = transform[1]\n",
    "    pixelHeight = -transform[5]\n",
    "\n",
    "    data = band.ReadAsArray(0, 0, cols, rows)\n",
    "\n",
    "    x0, y0, x1, y1 = coordinates\n",
    "    x0p = int((x0 - xOrigin) / pixelWidth)\n",
    "    y0p = int((yOrigin - y0 ) / pixelHeight)\n",
    "    x1p = int((x1 - xOrigin) / pixelWidth)\n",
    "    y1p = int((yOrigin - y1 ) / pixelHeight)\n",
    "    return x0p, y0p, x1p, y1p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse geojson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:36:03.089718Z",
     "start_time": "2018-10-03T05:36:03.086052Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download all necessary geojson files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:36:07.325866Z",
     "start_time": "2018-10-03T05:36:04.088820Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "#list of all debris annotated from UoH\n",
    "with open(\"{}/final_marine_debris_database_NI_UTM4N_boxes.geojson\".format(root_folder)) as f:\n",
    "    geo_json = json.load(f)\n",
    "len(geo_json['features'])\n",
    "debris_boxes = geo_json['features']\n",
    "\n",
    "\n",
    "with open(\"{}/niihau_tileindex.geojson\".format(root_folder)) as f:\n",
    "    tiles_geo_json = json.load(f)\n",
    "len(tiles_geo_json['features'])\n",
    "tiles_features = tiles_geo_json['features']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:36:14.094073Z",
     "start_time": "2018-10-03T05:36:14.076313Z"
    }
   },
   "outputs": [],
   "source": [
    "islands = set()\n",
    "for d in debris_boxes:\n",
    "    islands.add(d['properties']['island'])\n",
    "print(islands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:36:15.422520Z",
     "start_time": "2018-10-03T05:36:15.403370Z"
    }
   },
   "outputs": [],
   "source": [
    "#filter out specific data that we are looking for\n",
    "\n",
    "\n",
    "target_islands = [\"NI\"]\n",
    "def filter_debris_per_islands(target_islands=[]):\n",
    "    objects = ['T','V','N','B','M','P','C','L','F','W','O']\n",
    "    geo_json_in_search = []\n",
    "    set_of_objs = set()\n",
    "    for d in debris_boxes:\n",
    "        if d['properties']['type'] not in objects:\n",
    "            print(\"unknown object {}\".format(d['properties']['type']))\n",
    "        if d['properties']['island'] in target_islands:\n",
    "            geo_json_in_search.append(d)\n",
    "        set_of_objs.add(d['properties']['type'])\n",
    "\n",
    "    print(\"# of debris :{}\".format(len(geo_json_in_search)))\n",
    "    return geo_json_in_search\n",
    "print(set_of_objs)\n",
    "# Debris categories:\n",
    "# B = Buoys and floats\n",
    "# C = Cloth\t\n",
    "# F = Foam \n",
    "# L = Line (single pieces of rope, not net)\n",
    "# M = Metal\n",
    "# N = Net\n",
    "# P = Plastic\n",
    "# T = Tire\n",
    "# W = Processed wood\n",
    "# V = Vessel\n",
    "# O = Other "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:40:19.022728Z",
     "start_time": "2018-10-03T05:40:19.015688Z"
    }
   },
   "outputs": [],
   "source": [
    "len(geo_json_in_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:37:51.835426Z",
     "start_time": "2018-10-03T05:37:51.827077Z"
    }
   },
   "outputs": [],
   "source": [
    "geo_json_in_search[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:42:36.535301Z",
     "start_time": "2018-10-03T05:41:39.602640Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#find corresponding tile\n",
    "tile_with_debris = []\n",
    "tile_without_debris = set()\n",
    "unique_debris_image_set = {}\n",
    "max_number_of_negative_images = 10000\n",
    "stop_at_reached_at_max_negative = False\n",
    "print(\"searching {}\".format(len(geo_json_in_search)))\n",
    "\n",
    "\n",
    "bucket_name = 'hawaii-marine-debris'\n",
    "\n",
    "s3key_path_template = \"niihau/jpg/{}\"\n",
    "\n",
    "downloaded_tile = set()\n",
    "csv_rows = []\n",
    "\n",
    "print(\"Search for tile image based on annotation geojson\")\n",
    "for tile in tiles_features:\n",
    "    x0,y0,x1,y1 = find_min_xy(tile['geometry']['coordinates'][0]) \n",
    "    has_debris = False\n",
    "    \n",
    "    for debris in geo_json_in_search:\n",
    "        target = find_min_xy(debris['geometry']['coordinates'][0])\n",
    "        if x0 < target[0] and y0 < target[1] and  x1 > target[2] and y1 > target[3]:\n",
    "            print(\"with debris--{} unique debris -- {} without debris--{} \".format(len(tile_with_debris),len(unique_debris_image_set), len(tile_without_debris)),end='\\r')\n",
    "            json = {'label': d['properties']['type'],\n",
    "             'annotation': target,\n",
    "             'image_s3':tile['properties']['s3_path'],\n",
    "             'unique_pt_id': debris['properties']['unique_pt_id']\n",
    "            }\n",
    "            tile_with_debris.append(json)\n",
    "            unique_debris_image_set[debris['properties']['unique_pt_id']]=tile['properties']['s3_path']\n",
    "            debris['s3_key']=tile['properties']['s3_path']\n",
    "            has_debris = True\n",
    "\n",
    "    if not has_debris:\n",
    "        tile_without_debris.add(tile['properties']['tile_name'])\n",
    "        if stop_at_reached_at_max_negative and len(tile_without_debris)>max_number_of_negative_images:\n",
    "            break\n",
    "    if len(unique_debris_image_set)>=len(geo_json_in_search) and len(tile_without_debris)>max_number_of_negative_images:\n",
    "        break\n",
    "\n",
    "print(\"with debris--{} without debris--{}\".format(len(tile_with_debris),len(tile_without_debris)),end='\\r')\n",
    "#just find the first one for now. and let's think about how to deal with second images later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# max_number_of_negative_images = 10000\n",
    "# tile_without_debris = tile_without_debris[:max_number_of_negative_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T16:22:16.691245Z",
     "start_time": "2018-10-02T23:13:56.927Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for tif_name in tile_without_debris:\n",
    "    s3filepath = debris['image_s3'].replace('https://s3-us-west-2.amazonaws.com/hawaii-marine-debris/','')\n",
    "    tmpfile = \"{}/images/niihau/{}\".format(root_folder, os.path.basename(s3filepath))\n",
    "\n",
    "    if tmpfile not in downloaded_tile:\n",
    "        s3_resource.Bucket(bucket_name).download_file(s3filepath, tmpfile)\n",
    "        downloaded_tile.add(tmpfile)\n",
    "    jpg_path = convert_tif_to_jpeg(tmpfile)    \n",
    "    s3_key = s3key_path_template.format(os.path.basename(jpg_path))\n",
    "    print(\"Uploaded %s: %s -> %s -> %s\" % (len(csv_rows),tmpfile, jpg_path, s3_key), end='\\r')\n",
    "    if tmpfile not in downloaded_tile:\n",
    "        try:\n",
    "            s3_client.head_object(\n",
    "                Bucket=bucket_name,\n",
    "                Key=s3_key\n",
    "            )\n",
    "        except:\n",
    "            upload_to_s3(jpg_path, s3_key)\n",
    "    csv_rows.append((s3_key,\"\",\"\",\"\",\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('negative_tiles.csv','wb') as out:\n",
    "    csv_out=csv.writer(out)\n",
    "    csv_out.writerow(['s3_key','x0', 'y0','x1','y1', 'label'])\n",
    "    for row in csv_rows:\n",
    "        csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3_client.upload_file('negative_tiles.csv', bucket_name, \"niihau/negative_tiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T00:16:59.445564Z",
     "start_time": "2018-09-15T23:23:39.909190Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"convert image to JPEG, and convert bounding box to pixels\")\n",
    "\n",
    "for debris in tile_with_debris:\n",
    "    s3filepath = debris['image_s3'].replace('https://s3-us-west-2.amazonaws.com/hawaii-marine-debris/','')\n",
    "    tmpfile = \"{}/images/niihau/{}\".format(root_folder, os.path.basename(s3filepath))\n",
    "\n",
    "    if tmpfile not in downloaded_tile:\n",
    "        s3_resource.Bucket(bucket_name).download_file(s3filepath, tmpfile)\n",
    "        downloaded_tile.add(tmpfile)\n",
    "    \n",
    "    pixel_coordinates = get_pixel_coordinates(tmpfile, debris['annotation'])\n",
    "    jpg_path = convert_tif_to_jpeg(tmpfile)    \n",
    "    s3_key = s3key_path_template.format(os.path.basename(jpg_path))\n",
    "    print(\"Uploaded %s: %s -> %s -> %s\" % (len(csv_rows),tmpfile, jpg_path, s3_key), end='\\r')\n",
    "    if tmpfile not in downloaded_tile:\n",
    "        try:\n",
    "            s3_client.head_object(\n",
    "                Bucket=bucket_name,\n",
    "                Key=s3_key\n",
    "            )\n",
    "        except:\n",
    "            upload_to_s3(jpg_path, s3_key)\n",
    "    csv_rows.append((s3_key,)+ pixel_coordinates+(debris['label'],))\n",
    "    #free up storage once it's uploaded\n",
    "#     os.remove(jpg_path)\n",
    "#     os.remove(tmpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-16T00:30:57.307115Z",
     "start_time": "2018-09-16T00:30:57.300513Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "print(len(csv_rows))\n",
    "\n",
    "with open('annotated_marine_debris.csv','wb') as out:\n",
    "    csv_out=csv.writer(out)\n",
    "    csv_out.writerow(['s3_key','x0', 'y0','x1','y1', 'label'])\n",
    "    for row in csv_rows:\n",
    "        csv_out.writerow(row)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3_client.upload_file('annotated_marine_debris.csv', bucket_name, \"niihau/annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotated = pd.read_csv('annotated_marine_debris.csv',encoding='utf-8')\n",
    "not_annotated = pd.read_csv('negative_tiles.csv',encoding='utf-8')\n",
    "all_tiles_df = annotated.union(not_annotated)\n",
    "all_tiles_df.to_csv(\"all_tiles.csv\", encoding='utf-8')\n",
    "s3_client.upload_file('all_tiles.csv', bucket_name, \"niihau/all_tiles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T17:16:57.789342Z",
     "start_time": "2018-10-02T17:16:57.238287Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto\n",
    "\n",
    "s3 = boto.connect_s3(profile_name='hawaii')\n",
    "bucket = s3.get_bucket('hawaii-marine-debris')\n",
    "\n",
    "for o in bucket.list(prefix='lanai/', delimiter='/'):\n",
    "    print(o.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:22:43.991830Z",
     "start_time": "2018-10-03T05:22:41.922490Z"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "info_df=None\n",
    "tile_img_with_debris = []\n",
    "tile_img_without_debris = []\n",
    "for o in bucket.list(prefix='lanai/615/'):\n",
    "    if o.name.endswith('.csv'):\n",
    "        print(o.name)\n",
    "        obj = s3_client.get_object(Bucket=bucket_name, Key='lanai/2462/2462.tif.csv')\n",
    "        info_df = pd.read_csv(io.BytesIO(obj['Body'].read()),names=['img_name','x0','x1','y0','y1'],delimiter=';')\n",
    "        \n",
    "info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T05:25:00.659459Z",
     "start_time": "2018-10-03T05:25:00.627513Z"
    }
   },
   "outputs": [],
   "source": [
    "debris_json = filter_debris_per_islands([\"lanai\"])\n",
    "df_with_debris=None\n",
    "\n",
    "for debris in debris_json:\n",
    "    target = find_min_xy(debris['geometry']['coordinates'][0])\n",
    "    df_with_debris = info_df.filter(\"x0 < {} and y0 <{} and x1 > {} and y1 > {}\".format(target[0],target[1],target[2],target[3]))\n",
    "    if len(df_with_debris)>0:\n",
    "        break\n",
    "        \n",
    "df_with_debris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s3key_path_template = \"{island}/{img_folder}/{img_key}\"\n",
    "\n",
    "# downloaded_tile = set()\n",
    "# csv_rows = []\n",
    "\n",
    "# print(\"Search for tile image based on annotation geojson\")\n",
    "# for tile in tiles_features:\n",
    "#     x0,y0,x1,y1 = find_min_xy(tile['geometry']['coordinates'][0]) \n",
    "#     has_debris = False\n",
    "    \n",
    "#     for debris in geo_json_in_search:\n",
    "#         target = find_min_xy(debris['geometry']['coordinates'][0])\n",
    "#         if x0 < target[0] and y0 < target[1] and  x1 > target[2] and y1 > target[3]:\n",
    "#             print(\"with debris--{} without debris--{}\".format(len(tile_with_debris),len(tile_without_debris)),end='\\r')\n",
    "#             json = {'label': d['properties']['type'],\n",
    "#              'annotation': target,\n",
    "#              'image_s3':tile['properties']['s3_path'],\n",
    "#              'unique_pt_id': debris['properties']['unique_pt_id']\n",
    "#             }\n",
    "#             tile_with_debris.append(json)\n",
    "#             debris['s3_key']=tile['properties']['s3_path']\n",
    "#             has_debris = True\n",
    "\n",
    "#     if not has_debris:\n",
    "#         tile_without_debris.add(tile['properties']['tile_name'])\n",
    "#         if stop_at_reached_at_max_negative and len(tile_without_debris)>max_number_of_negative_images:\n",
    "#             break\n",
    "\n",
    "# print(\"with debris--{} without debris--{}\".format(len(tile_with_debris),len(tile_without_debris)),end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T04:40:56.381455Z",
     "start_time": "2018-10-03T04:40:55.453812Z"
    }
   },
   "outputs": [],
   "source": [
    "# # for all other islands, it's already converted to JPG.\n",
    "# # and the coordinates are stored in folder/csv\n",
    "\n",
    "# islands = ['oahu','lanai','kauai','hawaii']\n",
    "# islands = ['lanai']\n",
    "\n",
    "# for i in islands:\n",
    "#     resp = s3_client.list_objects_v2(Bucket = 'hawaii-marine-debris',\n",
    "#                                      Prefix='{island}/lanai/596/'.format(island=i), \n",
    "#                                     ) \n",
    "#     for obj in resp['Contents']:\n",
    "#         print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T00:19:09.693949Z",
     "start_time": "2018-10-01T00:19:09.687363Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # then find out if any of the images is overlapped with debris\n",
    "# for tile in tiles_features:\n",
    "\n",
    "#     #local file path\n",
    "#     tmpfile = \"{}/images/niihau/{}\".format(root_folder, os.path.basename(key))\n",
    "\n",
    "#     if tmpfile not in downloaded_tile:\n",
    "#         s3_resource.Bucket(bucket_name).download_file(key, tmpfile)\n",
    "#         downloaded_tile.add(tmpfile)\n",
    "#     #make sure none of the debris overlap it\n",
    "#     found_debris = False\n",
    "    \n",
    "#     for debris in geo_json_in_search:\n",
    "#         target = find_min_xy(debris['geometry']['coordinates'][0])\n",
    "        \n",
    "#             x0,y0,x1,y1 = find_min_xy(tile['geometry']['coordinates'][0]) \n",
    "#             if x0 < target[0] and y0 < target[1] and  x1 > target[2] and y1 > target[3]:\n",
    "#                 json = {'label': d['properties']['type'],\n",
    "#                  'annotation': target,\n",
    "#                  'image_s3':tile['properties']['s3_path'],\n",
    "#                 }\n",
    "#                 tile_with_debris.append(json)\n",
    "#                 print(\"found--{}\".format(len(tile_with_debris)),end='\\r')\n",
    "#                 found_debris = True\n",
    "#                 break\n",
    "#         if found_debris:\n",
    "#             break\n",
    "\n",
    "\n",
    "#         pixel_coordinates = get_pixel_coordinates(tmpfile, debris['annotation'])\n",
    "#         jpg_path = convert_tif_to_jpeg(tmpfile)    \n",
    "#         s3_key = s3key_path_template.format(os.path.basename(jpg_path))\n",
    "#         print(\"Uploaded %s: %s -> %s -> %s\" % (len(csv_rows),tmpfile, jpg_path, s3_key), end='\\r')\n",
    "#         if tmpfile not in downloaded_tile:\n",
    "#             try:\n",
    "#                 s3_client.head_object(\n",
    "#                     Bucket=bucket_name,\n",
    "#                     Key=s3_key\n",
    "#                 )\n",
    "#             except:\n",
    "#                 upload_to_s3(jpg_path, s3_key)\n",
    "#         csv_rows.append((s3_key,)+ pixel_coordinates+(debris['label'],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niihau_tileindex.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T15:25:41.800014Z",
     "start_time": "2018-09-15T15:25:41.774530Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-15T15:25:48.136001Z",
     "start_time": "2018-09-15T15:25:46.348915Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3_client.upload_file('annotated_marine_debris.csv', bucket_name, \"niihau/annotations.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
