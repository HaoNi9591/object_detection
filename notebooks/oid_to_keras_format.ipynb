{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import argparse\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# import simplejson as json\n",
    "annotations_file = \"../open_images/train-annotations-bbox.csv\"\n",
    "descriptions_file=\"../open_images/class-descriptions-boxable.csv\"\n",
    "\n",
    "#download from google big-query, through web or API\n",
    "image_map_file=\"marine_objs.json\"\n",
    "image_root = \"../open_images/aerial_marine_objs\"\n",
    "destination_root = \".\"\n",
    "\n",
    "with_small_image = True\n",
    "image_key_name = 'thumbnail_300k_url'\n",
    "if not with_small_image:\n",
    "    image_key_name = original_url\n",
    "\n",
    "    \n",
    "#open image dataset labels that you want    \n",
    "labels = ['/m/0199g', '/m/019jd', '/m/019w40', '/m/04dr76w', '/m/05gqfk',\n",
    "       '/m/083wq', '/m/0h9mv','']\n",
    "\n",
    "image_lookup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_classes = pd.read_csv(descriptions_file,names=['label','description'])\n",
    "target_labels = labeled_classes[labeled_classes['description'].isin([\"Surfboard\",\"Boat\",\"Plastic bag\", \"Tire\",\"Bottle\",\"Bicycle\",\"Wheel\"])]\n",
    "labels = target_labels['label'].values\n",
    "descriptions = target_labels['description'].values\n",
    "target_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make sure it's parsable\n",
    "infile = open(image_map_file, 'r')\n",
    "firstLine = infile.readline()\n",
    "d = json.loads(firstLine)\n",
    "iid = d['image_id']\n",
    "# '{\"image_id\":\"3894576d8d7f9cd1\",\"original_url\":\"https://farm2.staticflickr.com/3513/3974970554_11da5a46e6_o.jpg\",\"confidence\":\"1.0\"}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#this would automatically dedup\n",
    "def bigquery_result_to_image_lookup(image_map_file):\n",
    "    image_lookup = {}\n",
    "    \n",
    "    with open(image_map_file, 'r',encoding='utf8') as data_file:\n",
    "        json_data = data_file.read()\n",
    "    \n",
    "    json_str_array = json_data.split(\"\\n\")\n",
    "    jsons = []\n",
    "    \n",
    "    for st in json_str_array:\n",
    "        try:\n",
    "            jsons.append(json.loads(st))\n",
    "        except:\n",
    "            print(\"failed at {}\".format(len(jsons)))\n",
    "#             break\n",
    "    for j in jsons:\n",
    "        j['filename'] = os.path.basename(j[image_key_name])    \n",
    "        image_lookup[j[\"image_id\"]] = j\n",
    "    return image_lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lookup = bigquery_result_to_image_lookup(image_map_file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def format_annotations(annotation_path,description_table, labels, small_image=True, debug=False):\n",
    "    annotations = []\n",
    "    ids = []\n",
    "    trainable_classes = labels\n",
    "        \n",
    "    with open(annotation_path) as annofile:\n",
    "        reader = csv.reader(annofile)\n",
    "        next(reader, None)  # skip the headers\n",
    "        for row in reader:\n",
    "            if row[0]==\"ImageID\":\n",
    "                continue\n",
    "            annotation = {'id': row[0], 'label': row[2], 'confidence': row[3], 'xratio0': row[4],\n",
    "                          'xratio1': row[5], 'yratio0': row[6], 'yratio1': row[7]}\n",
    "            if annotation['label'] in trainable_classes and annotation['id'] in image_lookup:                \n",
    "                try:\n",
    "                    image_filename = image_lookup[annotation['id']]['filename']\n",
    "                    image_path = \"{}/{}\".format(image_root, image_filename)\n",
    "                    pil_im = Image.open(image_path, 'r')\n",
    "                    annotation['width'] = pil_im.width\n",
    "                    annotation['height'] = pil_im.height\n",
    "                    #keras retinanet only accepts absolute positions\n",
    "                    annotation['x1'] = round(pil_im.width * float(annotation['xratio0']))\n",
    "                    annotation['x2'] = round(pil_im.width * float(annotation['xratio1']))\n",
    "                    annotation['y1'] = round(pil_im.height * float(annotation['yratio0']))\n",
    "                    annotation['y2'] = round(pil_im.height * float(annotation['yratio1']))\n",
    "                    annotation['class']= description_table[row[2]]\n",
    "                    annotation['file_path'] = image_path\n",
    "\n",
    "                    annotations.append(annotation)\n",
    "                    ids.append(row[0])\n",
    "                except:\n",
    "                    if debug:\n",
    "                        print(\"{} may not be available anymore\".format(annotation['id']))\n",
    "            \n",
    "            \n",
    "    ids = dedupe(ids)\n",
    "    return annotations, ids\n",
    "\n",
    "annotations, ids = format_annotations(annotations_file,description_table,labels, with_small_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure JSON looks ok\n",
    "image_lookup[iid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_filename = image_lookup[iid]['filename']\n",
    "# ubuntu_image_root = \"/home/ubuntu/object_detection/jelly_fishes\"\n",
    "image_path = \"{}/{}\".format(image_root, image_filename)\n",
    "print(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "pil_im = Image.open(image_path, 'r')\n",
    "imshow(np.asarray(pil_im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pil_im.width)\n",
    "print(pil_im.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Export to csv \n",
    "- that you can use this with https://github.com/fizyr/keras-retinanet or some other object detection framework\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "keras_annotations=[]\n",
    "for a in annotations:\n",
    "    keras_annotations.append({ keras_key: a[keras_key] for keras_key in ['file_path', 'x1', 'y1', 'x2', 'y2', 'class'] })\n",
    "\n",
    "    \n",
    "with open(\"{}/annotations.csv\".format(destination_root), 'w') as f: \n",
    "    w = csv.DictWriter(f, keras_annotations[0].keys())\n",
    "    w.writerows(keras_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_images(saved_images_path, resized_images_path, points):\n",
    "    cleaned_points = []\n",
    "    for point in tqdm(points, desc=\"checking if images are valid from label index\"):\n",
    "            try:\n",
    "                stored_path = os.path.join(saved_images_path, point['id'] + '.jpg')\n",
    "                im = Image.open(stored_path)\n",
    "                im.verify()\n",
    "                # Now that the image is verified,\n",
    "                # lets rescale it and overwrite.\n",
    "                im.thumbnail((256, 256))\n",
    "                if resized_images_path:\n",
    "                    resized_path = os.path.join(resized_images_path, point['id'] + '.jpg')\n",
    "                    im.save(resized_path, 'JPG')\n",
    "                else:\n",
    "                    os.remove(stored_path)\n",
    "                    im.save(stored_path, 'JPG')\n",
    "                cleaned_points.append(point)\n",
    "            except:\n",
    "                pass\n",
    "    return cleaned_points\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
