{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T07:10:08.150692Z",
     "start_time": "2018-09-26T07:10:07.143230Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "import os \n",
    "import boto3\n",
    "from datetime import datetime\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "root_folder = os.getcwd()\n",
    "root_folder = \"/home/paperspace/data\"\n",
    "print(root_folder)\n",
    "image_root = '/home/paperspace/data/images/niihau'\n",
    "# local_jpg_path = \"/home/paperspace/data/images/niihau/\"+os.path.basename(row.s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T07:10:08.318303Z",
     "start_time": "2018-09-26T07:10:08.152705Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3 \n",
    "boto3.setup_default_session(profile_name='hawaii')\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')\n",
    "bucket_name = 'hawaii-marine-debris'\n",
    "version='v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T07:10:09.640331Z",
     "start_time": "2018-09-26T07:10:08.321876Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "test_annotations_key = \"ml/{}/data/keras_annotations_test.csv\".format(version)\n",
    "local_test_annotation_path = \"{}/keras_annotations_test.csv\".format(root_folder)\n",
    "s3_resource.Bucket(bucket_name).download_file(test_annotations_key, local_test_annotation_path)\n",
    "\n",
    "# obj = s3_client.get_object(Bucket=bucket_name, Key=test_annotations_key)\n",
    "test_annotation_df = pd.read_csv(local_test_annotation_path, encoding='utf-8',names=['image_path','x0','y0','x1','y1','label'])\n",
    "test_annotation_df[:5]\n",
    "\n",
    "\n",
    "annotations_key = \"ml/{}/data/keras_annotations_train.csv\".format(version)\n",
    "annotation_path = \"{}/keras_annotations_train_{}.csv\".format(root_folder,version)\n",
    "s3_resource.Bucket(bucket_name).download_file(annotations_key, annotation_path)\n",
    "\n",
    "# obj = s3_client.get_object(Bucket=bucket_name, Key=test_annotations_key)\n",
    "annotation_df = pd.read_csv(annotation_path, encoding='utf-8',names=['image_path','x0','y0','x1','y1','label'])\n",
    "annotation_df = annotation_df.append(test_annotation_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotation_df)\n",
    "# test_annotation_df = annotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'image_path' in annotation_df.columns:\n",
    "    annotation_df['s3_key'] = annotation_df['image_path'].apply(lambda s: s.replace(image_root,'niihau/jpg')).apply(lambda s: s.replace(\"/home/paperspace/data/images/niihau\",'niihau/jpg'))\n",
    "annotation_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T07:10:09.648825Z",
     "start_time": "2018-09-26T07:10:09.643332Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'image_path' in test_annotation_df.columns:\n",
    "    test_annotation_df['s3_key'] = test_annotation_df['image_path'].apply(lambda s: s.replace(image_root,'niihau/jpg')).apply(lambda s: s.replace(\"/home/paperspace/data/images/niihau\",'niihau/jpg'))\n",
    "if version!='v1':\n",
    "    test_annotation_df['label'] = test_annotation_df['label'].replace({'B':'Buoys','C': 'Cloth','F':'Foam','L':'Line','M':'Metal','N':'Net','P':'Plastic','T':'Tire','W':'wood','V':'Boat'})\n",
    "test_annotation_df.groupby('label').size().reset_index(name='counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## with negative images\n",
    "\n",
    "len(test_annotation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T07:14:17.952780Z",
     "start_time": "2018-09-26T07:14:17.945236Z"
    }
   },
   "outputs": [],
   "source": [
    "test_annotation_df = test_annotation_df.sort_values('s3_key')\n",
    "test_annotation_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T07:14:42.847715Z",
     "start_time": "2018-09-26T07:14:42.840812Z"
    }
   },
   "outputs": [],
   "source": [
    "first_row = test_annotation_df.iloc[0]\n",
    "local_image_path = \"{}/{}\".format(root_folder, os.path.basename(first_row['s3_key']))\n",
    "print(first_row['s3_key'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T05:12:48.358338Z",
     "start_time": "2018-09-25T05:12:45.414448Z"
    }
   },
   "outputs": [],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_session():\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    return tf.Session(config=config)\n",
    "\n",
    "# use this environment flag to change which GPU to use\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "keras.backend.tensorflow_backend.set_session(get_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T06:23:05.367947Z",
     "start_time": "2018-09-25T06:23:05.025738Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def display_objects(image_file , actual=[], threshold = 0.1):\n",
    "    image = read_image_bgr(image_file)\n",
    "    \n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(40, 40))\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    # image, scale = resize_image(image)\n",
    "\n",
    "    # process image\n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    print(\"processing time: \", time.time() - start)\n",
    "    print(\"detected {} labels\".format(len(labels[0])))\n",
    "    \n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        # scores are sorted so we can break\n",
    "        if score < threshold :\n",
    "            print(\"not enough confidence\")\n",
    "            break\n",
    "        \n",
    "        color = label_color(label)\n",
    "        print(box)\n",
    "        b = box.astype(int)\n",
    "        draw_box(draw, b, color=color)\n",
    "        if score >= threshold:\n",
    "            caption = \"{} {:.3f}\".format(label_lookup[label], score)\n",
    "            print(caption)\n",
    "        else:\n",
    "            caption = \"\"\n",
    "        draw_caption(draw, b, caption)\n",
    "    for obj in actual:\n",
    "        draw_box(draw, obj, color=[31  , 0   , 255])\n",
    "    plt.figure(figsize=(120, 120))\n",
    "\n",
    "    plt.imshow(draw)\n",
    "    plt.show()\n",
    "    \n",
    "def detect_objects(image_file, threshold = 0.1):\n",
    "    image = read_image_bgr(image_file)\n",
    "    detected_objects = []\n",
    "    image = preprocess_image(image)\n",
    "    start = time.time()\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "    max_items = 10\n",
    "    \n",
    "    for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "        if score < threshold:\n",
    "            break\n",
    "        b = box.astype(int)\n",
    "        detected_objects.append({'x1':b[0], 'y1':b[1], 'x2': b[2], 'y2':b[3],'label':label,'score':score})\n",
    "        if len(detected_objects)>=max_items:\n",
    "            break\n",
    "    return detected_objects\n",
    "    \n",
    "def detect_debris(row):\n",
    "    local_image_path = \"{}/{}\".format(root_folder, os.path.basename(first_row['s3_key']))\n",
    "    if not os.path.isfile(local_image_path):\n",
    "        s3_resource.Bucket(bucket_name).download_file(row['s3_key'], local_image_path)\n",
    "    display_objects(local_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T06:02:53.821389Z",
     "start_time": "2018-09-25T06:02:53.740804Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_iou(bb1, bb2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bb1 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x1, y1) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "    bb2 : dict\n",
    "        Keys: {'x1', 'x2', 'y1', 'y2'}\n",
    "        The (x, y) position is at the top left corner,\n",
    "        the (x2, y2) position is at the bottom right corner\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        in [0, 1]\n",
    "    \"\"\"\n",
    "    assert bb1['x1'] <= bb1['x2']\n",
    "    assert bb1['y1'] <= bb1['y2']\n",
    "    assert bb2['x1'] <= bb2['x2']\n",
    "    assert bb2['y1'] <= bb2['y2']\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou\n",
    "\n",
    "#bb1: predicted\n",
    "#bb2: actual\n",
    "def overlapped_type(bb1, bb2):\n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "    \n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "    \n",
    "    if x_left==bb1['x1'] and y_top==bb1['y1'] and x_right==bb1['x2'] and y_bottom==bb1['y2']:\n",
    "        return 'outside'\n",
    "    elif x_left==bb2['x1'] and y_top==bb2['y1'] and x_right==bb2['x2'] and y_bottom==bb2['y2']:\n",
    "        return 'within'\n",
    "    else:\n",
    "        return 'overwrapped'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/tmp/model_{}_10_6.h5\".format(version)\n",
    "print(model_path)\n",
    "model_key = \"ml/model/debris_model_{}_10_6.h5\".format(version)\n",
    "print(model_key)\n",
    "if not os.path.isfile(model_path):\n",
    "    s3_resource.Bucket(bucket_name).download_file(model_key, model_path)\n",
    "\n",
    "model = models.load_model(model_path, backbone_name='resnet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = \"/tmp/labels_{}.csv\".format(version)\n",
    "s3_resource.Bucket(bucket_name).download_file('ml/{}/data/labels.csv'.format(version), label_path)\n",
    "label_df = pd.read_csv(label_path,names=['label','id'])\n",
    "label_df\n",
    "label_lookup = label_df.set_index('id').T.to_dict('records')[0]\n",
    "label_lookup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotation_df['label_found'] = None\n",
    "test_annotation_df['wrong_label'] = None\n",
    "test_annotation_df['detected'] = None\n",
    "test_annotation_df['detected_bounding_type'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotation_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quick test with 1 test data set\n",
    "detection_per_image = {}\n",
    "\n",
    "row = test_annotation_df.iloc[0]\n",
    "x1, y1, x2, y2, label = row['x0'], row['y0'], row['x1'], row['y1'], row['label'] #42,347,849,1134\n",
    "annotation ={'x1':x1, 'x2':x2, 'y1':y1, 'y2':y2, 'label':label}\n",
    "\n",
    "local_image_path = \"{}/{}\".format(root_folder, os.path.basename(row['s3_key']))\n",
    "os.path.isfile(local_image_path)\n",
    "if not os.path.isfile(row.image_path) and not os.path.isfile(local_image_path):\n",
    "    print(\"downloading image\")\n",
    "    s3_resource.Bucket(bucket_name).download_file(row['s3_key'], local_image_path)\n",
    "print(\"image ready\",end='\\r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_annotation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate recall : how many did we get it and missed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T06:28:31.082637Z",
     "start_time": "2018-09-25T06:25:50.929556Z"
    }
   },
   "outputs": [],
   "source": [
    "num_found = 0\n",
    "processed = 0\n",
    "wrong_label = 0\n",
    "\n",
    "# needs to evaluate these\n",
    "new_detection =0 \n",
    "\n",
    "# deteobjs = detect_objects(local_image_path)\n",
    "all_debris_detected = []\n",
    "for i, row in test_annotation_df.iterrows():\n",
    "    x1, y1, x2, y2, label = row['x0'], row['y0'], row['x1'], row['y1'], row['label'] #42,347,849,1134\n",
    "    annotation ={'x1':x1, 'x2':x2, 'y1':y1, 'y2':y2, 'label':label}\n",
    "    local_image_path = \"{}/{}\".format(image_root, os.path.basename(row['s3_key']))\n",
    "\n",
    "    #download, if it's not there yet.\n",
    "    if not os.path.isfile(row.image_path) and not os.path.isfile(local_image_path):\n",
    "        s3_resource.Bucket(bucket_name).download_file(row['s3_key'], local_image_path)\n",
    "        print(\"image ready\",end='\\r')\n",
    "\n",
    "    if not local_image_path in detection_per_image:\n",
    "        deteobjs = detect_objects(local_image_path)\n",
    "        detection_per_image[local_image_path] = deteobjs\n",
    "        print(\"Detected objects\",end='\\r')\n",
    "    else:\n",
    "        deteobjs = detection_per_image[local_image_path]\n",
    "    found = False\n",
    "    for obj in deteobjs:\n",
    "        overlap_ratio =get_iou(obj,annotation)\n",
    "        if(overlap_ratio):\n",
    "            found = True\n",
    "            num_found +=1\n",
    "            test_annotation_df.loc[i, 'detected_bounding_type'] = overlapped_type(obj,annotation)\n",
    "            test_annotation_df.loc[i, 'detected'] = str(obj)\n",
    "            if version == \"v1\":\n",
    "                test_annotation_df.loc[i, 'label_found'] = label_lookup[str(obj['label'])]\n",
    "            else:\n",
    "                test_annotation_df.loc[i, 'label_found'] = label_lookup[obj['label']]\n",
    "            obj['overlapped_with_test_index'] = i\n",
    "        if obj['score'] >0.15:\n",
    "            obj['s3_key']=row['s3_key']\n",
    "            all_debris_detected.append(obj)\n",
    "        if obj['score'] <0.1:\n",
    "            break\n",
    "    processed +=1\n",
    "    message =(\"%s debris found out of %s\" % (num_found, processed))\n",
    "    print(message,end='\\r')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotation_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_debris_detected[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate precision : how many of detected were correct?\n",
    "print(\"%s debris found out of %s\" % (num_found, processed))\n",
    "len(all_debris_detected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(str(obj))\n",
    "# test_annotation_df.loc[1, 'detected'] = str(obj)\n",
    "test_annotation_df[test_annotation_df['detected_bounding_type'].isin(['within','outside','overwrapped'])].to_csv('bounding_box_detected_{}.csv'.format(version), encoding='utf-8')\n",
    "s3_client.upload_file('bounding_box_detected_{}.csv'.format(version), bucket_name, 'ml/result/{}_bounding_box_detected_{}.csv'.format(version, ts))\n",
    "test_annotation_df.to_csv(\"evaluation_result.csv\", encoding='utf-8')\n",
    "s3_client.upload_file('evaluation_result.csv', bucket_name, 'ml/result/evaluation_result_for_test{}_{}.csv'.format(version, ts))\n",
    "\n",
    "evaluation_key = \"ml/result/{}/evaluation_result.csv\".format(version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file('evaluation_result.csv', bucket_name, 'ml/result/{}/evaluation_result.csv'.format(version, ts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect against all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check against training data also. maybe we can use this as new annotations\n",
    "num_found = 0\n",
    "processed = 0\n",
    "# needs to evaluate these\n",
    "new_detection =0 \n",
    "\n",
    "\n",
    "##refactor this later\n",
    "\n",
    "target_df = annotation_df\n",
    "\n",
    "for i, row in target_df.iterrows():\n",
    "    x1, y1, x2, y2, label = row['x0'], row['y0'], row['x1'], row['y1'], row['label'] #42,347,849,1134\n",
    "    annotation ={'x1':x1, 'x2':x2, 'y1':y1, 'y2':y2, 'label':label}\n",
    "    local_image_path = \"{}/{}\".format(image_root, os.path.basename(row['s3_key']))\n",
    "\n",
    "    #download, if it's not there yet.\n",
    "    if not os.path.isfile(row.image_path) and not os.path.isfile(local_image_path):\n",
    "        s3_resource.Bucket(bucket_name).download_file(row['s3_key'], local_image_path)\n",
    "        print(\"image ready\",end='\\r')\n",
    "\n",
    "    if not local_image_path in detection_per_image:\n",
    "        deteobjs = detect_objects(local_image_path)\n",
    "        detection_per_image[local_image_path] = deteobjs\n",
    "        print(\"Detected objects\",end='\\r')\n",
    "    else:\n",
    "        deteobjs = detection_per_image[local_image_path]\n",
    "    \n",
    "    found = False\n",
    "    \n",
    "    for obj in deteobjs:\n",
    "        overlap_ratio =get_iou(obj,annotation)\n",
    "        if(overlap_ratio):\n",
    "            found = True\n",
    "            num_found +=1\n",
    "            target_df.loc[i, 'detected_bounding_type'] = overlapped_type(obj,annotation)\n",
    "            target_df.loc[i, 'detected'] = str(obj)\n",
    "            if version == \"v1\":\n",
    "                target_df.loc[i, 'label_found'] = label_lookup[str(obj['label'])]\n",
    "            else:\n",
    "                target_df.loc[i, 'label_found'] = label_lookup[obj['label']]\n",
    "            obj['overlapped_with_training_index'] = i\n",
    "        if obj['score'] >0.1:\n",
    "            obj['s3_key']=row['s3_key']\n",
    "            all_debris_detected.append(obj)\n",
    "        if obj['score'] <=0.1:\n",
    "            break\n",
    "    processed +=1\n",
    "    message =(\"%s debris found out of %s\" % (num_found, processed))\n",
    "    print(message,end='\\r')\n",
    "    \n",
    "#expect these to be really high accuracy. needs evalate for those it missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%s debris found out of %s and detected %s \" % (num_found, processed, len(all_debris_detected)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_to_csv\n",
    "\n",
    "import csv\n",
    "f = csv.writer(open('all_debris_detected.csv', \"w+\"))\n",
    "f.writerow([\"image_s3_key\",\"x1\", \"y1\", \"x2\", \"y2\", \"label\",\"score\",\"overlapped_test_index\",'overlapped_with_training_index'])\n",
    "\n",
    "for x in all_debris_detected:\n",
    "    val1, val2=\"\",\"\"\n",
    "    if \"overlapped_with_test_index\" in x:\n",
    "        val1=x[\"overlapped_with_test_index\"]\n",
    "    if \"overlapped_with_training_index\" in x:\n",
    "        val2=x[\"overlapped_with_training_index\"]\n",
    "    f.writerow([x[\"s3_key\"],\n",
    "                x[\"x1\"],\n",
    "                x[\"y1\"],\n",
    "                x[\"x2\"],\n",
    "                x[\"y2\"],\n",
    "                x[\"label\"],\n",
    "                x[\"score\"],\n",
    "                val1,val2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_detected = pd.read_csv('all_debris_detected.csv')\n",
    "print(len(all_detected))\n",
    "deduped_all_detected = all_detected.drop_duplicates()\n",
    "print(len(deduped_all_detected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_all_detected.to_csv(\"all_debris_detected_from_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file('all_debris_detected_from_all.csv', bucket_name, 'ml/result/{}/all_debris_detected_from_all.csv'.format(version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pik_filepath = \"detection_per_image.pkl\"\n",
    "\n",
    "with open(pik_filepath, \"wb\") as f:\n",
    "    pickle.dump(detection_per_image, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to open it\n",
    "with open('data.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    data = pickle.load(f)\n",
    "    pickle.load(\"detection_per_image.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####TODO:::\n",
    "\n",
    "## out of those we detected that we didn't have it before, upload to x to verify if it's the real debris.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head all_debris_detected.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "version| recall   | precision | notes |\n",
    "-------|----------|-----------|-------|\n",
    "v1     | 101/678  | 101/636   | without OID|\n",
    "v2     | 203/694  | 203/598   | with OID | \n",
    "v3     | 183/648  | 183/714   | with negative image and more type of debris|\n",
    "v3.10_6| 417/648  | 417/676   | 7 epochs with 5000 steps to avoid overfitting | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client.upload_file('all_debris_detected.csv', bucket_name, 'ml/result/{}/all_debris_detected.csv'.format(version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test_annotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_debris_detected.to_csv(\"all_debris_detected.csv\",encoding='utf-8')\n",
    "# s3_client.upload_file('all_debris_detected.csv', bucket_name, 'ml/result/{}/all_debris_detected.csv'.format(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_annotation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_annotation_df[~test_annotation_df.index.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annotation_df= test_annotation_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# test_annotation_df.iloc[0]\n",
    "\n",
    "annotated_df = test_annotation_df[~test_annotation_df[\"label\"].isnull()]\n",
    "non_annotated_df = test_annotation_df[test_annotation_df[\"label\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annotated_df.groupby('label').size().reset_index(name='counts')\n",
    "#wrong detection\n",
    "wrong_labeled = annotated_df[test_annotation_df['label_found'].notnull()][annotated_df['label_found']!=annotated_df['label']]\n",
    "correct_labled = annotated_df[test_annotation_df['label_found'].notnull()][annotated_df['label_found']==annotated_df['label']]\n",
    "\n",
    "stats = {\n",
    "    \"wrong_label\":len(wrong_labeled),\n",
    "    \"correct_label\":len(correct_labled),\n",
    "    \"missed\":len(annotated_df[annotated_df['label_found'].isna()]),\n",
    "}\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labled.groupby('label').size().reset_index(name='counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_labeled.groupby('label').size().reset_index(name='counts')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
